{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3luwvU1Exh0M",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EHr-OonvmHD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
    "#from keras.utils import to_categorical\n",
    "#from keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, MaxPooling2D, BatchNormalization, Dropout\n",
    "\n",
    "import PIL\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading in data, train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"./data/processed/train_less_labels_5.pkl\")\n",
    "test = pd.read_pickle(\"./data/processed/test_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### How to process images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.image_data\n",
    "train_y = train.drop([\"image_id\", \"labels\", \"image_data\"], axis = 1)\n",
    "test_X = test.image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Images have different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_width = 5000\n",
    "max_width = 0\n",
    "min_height = 5000\n",
    "max_height = 0\n",
    "widths = []\n",
    "heights = []\n",
    "for i in range(len(train_X)):\n",
    "  h, w, c = train_X.iloc[i].shape\n",
    "  widths.append(w)\n",
    "  heights.append(h)\n",
    "  #print(h, w, c)\n",
    "  if h > max_height:\n",
    "    max_height = h\n",
    "  elif h < min_height:\n",
    "    min_height = h\n",
    "  elif w > max_width:\n",
    "    max_width = w\n",
    "  elif w < min_width:\n",
    "    min_width = w\n",
    "print(\"min w-h\", min_width, min_height)\n",
    "print(\"max w-h\", max_width, max_height)\n",
    "print(f\"Avg w {sum(widths) / len(widths)} and h {sum(heights) / len(heights)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = np.array([[2,3],[4,4], [2,3]])\n",
    "a.shape\n",
    "train_X.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = PIL.Image.fromarray(train_X[0])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = deepcopy(train_X[0])\n",
    "h_centre = int(train_X[0].shape[0] / 2)\n",
    "w_centre = int(train_X[0].shape[1] / 2)\n",
    "print(w_centre, h_centre)\n",
    "ab = a[w_centre-200:w_centre + 200, h_centre - 142:h_centre + 142]\n",
    "im = PIL.Image.fromarray(ab)\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Cropping all images to the smallest image size loses a lot of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Resizing to avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "im = PIL.Image.fromarray(train_X[0])\n",
    "img_resized = im.resize((572, 432))\n",
    "img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "im = PIL.Image.fromarray(train_X[0])\n",
    "img_resized = im.resize((572, 432), PIL.Image.LANCZOS)\n",
    "img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "im = PIL.Image.fromarray(train_X[0])\n",
    "img_resized = im.resize((572, 432), PIL.Image.BICUBIC)\n",
    "img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_X_resized = []\n",
    "for i in range(len(train_X)):\n",
    "  im = PIL.Image.fromarray(train_X.iloc[i])\n",
    "  img_resized = im.resize((572, 432), PIL.Image.BICUBIC)\n",
    "  # to grayscale\n",
    "  #img_grayscaled = img_resized.convert(\"L\")\n",
    "  train_X_resized.append(np.array(img_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_X_resized = np.array(train_X_resized)\n",
    "im = PIL.Image.fromarray(train_X_resized[0])\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_X_normalized = train_X_resized / 255\n",
    "train_X_normalized[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#train_X_reshaped = train_X_normalized.reshape(-1, 432, 572, 1)\n",
    "#train_X_reshaped[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_y_np = train_y.to_numpy(\"float64\")\n",
    "len(train_y_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X_normalized, train_y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(432, 572, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Currently missing F1 metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Loss and accuracy on test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "#multilabel_confusion_matrix(y_test, preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get top 3 preds\n",
    "import heapq\n",
    "cols = train_y.columns.tolist()\n",
    "as_dataframe = pd.DataFrame(preds, columns = train_y.columns.tolist())\n",
    "min_treshold = 0.10\n",
    "row_results = []\n",
    "\n",
    "for index, row in as_dataframe.iterrows():\n",
    "    res = []\n",
    "    col = 0\n",
    "    values = row.to_numpy()\n",
    "    top3 = np.argpartition(values, -3)[-3:]\n",
    "    top3 = np.flip(top3[np.argsort(values[top3])])\n",
    "    \n",
    "    for top in top3:\n",
    "        if values[top] >= min_treshold:\n",
    "            res.append(cols[top])\n",
    "    row_results.append(res)\n",
    "    #print(res)\n",
    "print(row_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FpN9vSL7vmHh",
    "Sd5uo14XvmHk"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
